# Machine Learning Paper - Anomaly Detection Across Workflow Datasets

## ðŸŽ¯ Project Overview

This project implements and evaluates **6 anomaly detection models** across 12 workflow datasets using multiple modalities (text, tabular, graph) and approaches (3 supervised, 3 unsupervised).

## ðŸ“Š Datasets Analyzed

The following 12 workflow datasets were analyzed:
- `1000genome` - Genomics workflow
- `casa_nowcast` - Climate modeling  
- `casa_wind_speed` - Wind speed analysis
- `eht_difmap` - Event Horizon Telescope data processing
- `eht_imaging` - EHT imaging pipeline
- `eht_smili` - EHT SMILI processing
- `montage` - Astronomical image mosaicking
- `predict_future_sales` - Sales prediction workflow
- `pycbc_inference` - Gravitational wave inference
- `pycbc_search` - Gravitational wave search
- `somospie` - Solar dynamics analysis
- `variant_calling` - Genomic variant calling

## ðŸ¤– Models Implemented

### Supervised Learning (3 models)
- **GCN Graph Classification**: Graph-based anomaly detection
- **Random Forest Tabular**: Tabular-based anomaly detection
- **RoBERTa Text Classification**: Text-based anomaly detection

### Unsupervised Learning (3 models)
- **Graph Autoencoder (Fixed)**: Graph-based anomaly detection
- **Gaussian Mixture Model**: Tabular-based anomaly detection
- **Sentence-BERT + Isolation Forest**: Text-based anomaly detection


## ðŸ“ Project Structure

```
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ supervised/
â”‚   â”‚   â””â”€â”€ gcn_graph/          # GCN Graph Classification
â”‚   â”‚   â””â”€â”€ random_forest_tabular/          # Random Forest Tabular
â”‚   â”‚   â””â”€â”€ roberta_text/          # RoBERTa Text Classification
â”‚   â””â”€â”€ unsupervised/
â”‚       â””â”€â”€ graph_gae/       # Graph Autoencoder (Fixed)
â”‚       â””â”€â”€ tabular_gmm/       # Gaussian Mixture Model
â”‚       â””â”€â”€ text_sentence_bert/       # Sentence-BERT + Isolation Forest
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ supervised/                # Supervised learning reports
â”‚   â””â”€â”€ unsupervised/              # Unsupervised learning reports  
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ supervised/                # Supervised model scripts
â”‚   â”œâ”€â”€ unsupervised/              # Unsupervised model scripts
â”‚   â””â”€â”€ utils/                     # Utility and organization scripts
â””â”€â”€ data/                          # Dataset files
```

## ðŸš€ Usage

### Running Individual Models

```bash
# Supervised Models
python scripts/supervised/gcn_graph/train_*.py
python scripts/supervised/random_forest_tabular/train_*.py
python scripts/supervised/roberta_text/train_*.py

# Unsupervised Models
python scripts/unsupervised/graph_gae/train_*.py
python scripts/unsupervised/tabular_gmm/train_*.py
python scripts/unsupervised/text_sentence_bert/train_*.py
```

## ðŸ“Š Result Files

Each model directory contains:
- `*_results_summary.csv` - Performance metrics summary
- `*_confusion_matrices.png` - Confusion matrix visualizations  
- `*_roc_curves.png` - ROC curve plots
- `*_performance_summary.png` - Comprehensive performance analysis

## ðŸ† Key Findings

This comprehensive evaluation across multiple modalities and approaches provides insights into:
- **Best performing models** for each data type
- **Cross-modal performance** comparisons
- **Supervised vs unsupervised** effectiveness
- **Dataset-specific** anomaly patterns

## ðŸ“š Dependencies

```
torch>=1.9.0
transformers>=4.0.0
sentence-transformers>=2.0.0
scikit-learn>=1.0.0
pandas>=1.3.0
numpy>=1.21.0
matplotlib>=3.4.0
seaborn>=0.11.0
tqdm>=4.62.0
```

---

**ðŸŽ‰ Project Status: Complete**  
All models trained, evaluated, and results organized successfully!
